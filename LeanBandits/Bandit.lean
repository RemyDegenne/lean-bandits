/-
Copyright (c) 2025 Rémy Degenne. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: Rémy Degenne, Paulo Rauber
-/
import Mathlib

/-!
# Bandit

-/

open MeasureTheory ProbabilityTheory Filter Real Finset

open scoped ENNReal NNReal

/-- Measurable equivalence between `Iic 0 → α` and `α`. -/
def MeasurableEquiv.piIicZero (α : Type*) [MeasurableSpace α] :
    (Iic 0 → α) ≃ᵐ α :=
  have : Unique (Iic 0) := by simp only [mem_Iic, nonpos_iff_eq_zero]; exact Unique.subtypeEq 0
  MeasurableEquiv.funUnique _ _

namespace Bandits

variable {α R : Type*} {mα : MeasurableSpace α} {mR : MeasurableSpace R}

section MeasureSpace

/-- A stochastic, sequential algorithm. -/
structure Algorithm (α R : Type*) [MeasurableSpace α] [MeasurableSpace R] where
  /-- Policy or sampling rule: distribution of the next pull. -/
  policy : (n : ℕ) → Kernel (Iic n → α × R) α
  [h_policy : ∀ n, IsMarkovKernel (policy n)]
  /-- Distribution of the first pull. -/
  p0 : Measure α
  [hp0 : IsProbabilityMeasure p0]

/-- A bandit interaction between an agent described by a policy and an environment given by
reward distributions. -/
structure Bandit (α R : Type*) [MeasurableSpace α] [MeasurableSpace R] extends Algorithm α R where
  /-- Conditional distribution of the rewards given the arm pulled. -/
  ν : Kernel α R
  [hν : IsMarkovKernel ν]

instance (b : Bandit α R) : IsMarkovKernel b.ν := b.hν
instance (b : Bandit α R) (n : ℕ) : IsMarkovKernel (b.policy n) := b.h_policy n
instance (b : Bandit α R) : IsProbabilityMeasure b.p0 := b.hp0

namespace Bandit

/-- Kernel describing the distribution of the next arm-reward pair given the history up to `n`. -/
noncomputable
def stepKernel (b : Bandit α R) (n : ℕ) : Kernel (Iic n → α × R) (α × R) :=
  (b.policy n) ⊗ₖ b.ν.prodMkLeft (Iic n → α × R)

instance (b : Bandit α R) (n : ℕ) : IsMarkovKernel (b.stepKernel n) := by
  rw [stepKernel]
  infer_instance

@[simp]
lemma fst_stepKernel (b : Bandit α R) (n : ℕ) : (b.stepKernel n).fst = b.policy n := by
  rw [stepKernel, Kernel.fst_compProd]

@[simp]
lemma snd_stepKernel (b : Bandit α R) (n : ℕ) : (b.stepKernel n).snd = b.ν ∘ₖ b.policy n := by
  rw [stepKernel, Kernel.snd_compProd_prodMkLeft]

/-- Kernel sending a partial trajectory of the bandit interaction `Iic n → α × ℝ` to a measure
on `ℕ → α × ℝ`, supported on full trajectories that start with the partial one. -/
noncomputable def traj (b : Bandit α R) (n : ℕ) : Kernel (Iic n → α × R) (ℕ → α × R) :=
  ProbabilityTheory.Kernel.traj (X := fun _ ↦ α × R) b.stepKernel n

instance (b : Bandit α R) (n : ℕ) : IsMarkovKernel (b.traj n) := by
  rw [traj]
  infer_instance

/-- Measure on the sequence of arms pulled and rewards observed generated by the bandit. -/
noncomputable
def trajMeasure (b : Bandit α R) : Measure (ℕ → α × R) :=
  (b.traj 0) ∘ₘ ((b.p0 ⊗ₘ b.ν).map (MeasurableEquiv.piIicZero _).symm)

/-- Measure of an infinite stream of rewards from each arm. -/
noncomputable
def streamMeasure (b : Bandit α R) : Measure (ℕ → α → R) :=
  Measure.infinitePi fun _ ↦ Measure.infinitePi b.ν
deriving IsProbabilityMeasure

instance (b : Bandit α R) : IsProbabilityMeasure b.trajMeasure := by
  rw [Bandit.trajMeasure]
  have : IsProbabilityMeasure ((b.p0 ⊗ₘ b.ν).map (MeasurableEquiv.piIicZero _).symm) :=
    isProbabilityMeasure_map <| by fun_prop
  infer_instance

/-- Joint distribution of the sequence of arm pulled and rewards, and a stream of independent
rewards from all arms. -/
noncomputable
def measure (b : Bandit α R) : Measure ((ℕ → α × R) × (ℕ → α → R)) :=
  (b.trajMeasure).prod (b.streamMeasure)
deriving IsProbabilityMeasure

end Bandit

/-- `arm n` is the arm pulled at time `n`. This is a random variable on the measurable space
`ℕ → α × ℝ`. -/
def arm (n : ℕ) (h : ℕ → α × R) : α := (h n).1

/-- `reward n` is the reward at time `n`. This is a random variable on the measurable space
`ℕ → α × R`. -/
def reward (n : ℕ) (h : ℕ → α × R) : R := (h n).2

/-- `hist n` is the history up to time `n`. This is a random variable on the measurable space
`ℕ → α × R`. -/
def hist (n : ℕ) (h : ℕ → α × R) : Iic n → α × R := fun i ↦ h i

@[fun_prop]
lemma measurable_arm (n : ℕ) : Measurable (arm n (α := α) (R := R)) := by unfold arm; fun_prop

@[fun_prop]
lemma measurable_reward (n : ℕ) : Measurable (reward n (α := α) (R := R)) := by
  unfold reward; fun_prop

@[fun_prop]
lemma measurable_hist (n : ℕ) : Measurable (hist n (α := α) (R := R)) := by unfold hist; fun_prop

/-- Filtration of the bandit process. -/
def ℱ (α : Type*) [MeasurableSpace α] :
    Filtration ℕ (inferInstance : MeasurableSpace (ℕ → α × R)) :=
  MeasureTheory.Filtration.piLE (X := fun _ ↦ α × R)

lemma condDistrib_arm_reward [StandardBorelSpace α] [Nonempty α]
    [StandardBorelSpace R] [Nonempty R] (b : Bandit α R) (n : ℕ) :
    condDistrib (fun h ↦ (arm n h, reward n h)) (hist n) b.trajMeasure = b.stepKernel n := by
  sorry

lemma condDistrib_reward [StandardBorelSpace R] [Nonempty R] (b : Bandit α R) (n : ℕ) :
    condDistrib (reward n) (arm n) b.trajMeasure = b.ν := by
  sorry

lemma condDistrib_arm [StandardBorelSpace α] [Nonempty α] [StandardBorelSpace R] [Nonempty R]
    (b : Bandit α R) (n : ℕ) :
    condDistrib (arm n) (hist n) b.trajMeasure = b.policy n := by
  rw [← b.fst_stepKernel, ← condDistrib_arm_reward]
  sorry

end MeasureSpace

end Bandits
