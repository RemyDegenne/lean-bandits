\chapter{Bandit algorithms}

\section{Explore-Then-Commit}

Note: times start at 0 to be consistent with Lean.

Note: we will describe the algorithm by writing $A_t = ...$, but our formal bandit model needs a policy $\pi_t$ that gives the distribution of the arm to pull. What me mean is that $\pi_t$ is a Dirac distribution at that arm.

\inputleannode{def:etcAlgorithm}


\inputleannode{lem:pullCount_etcAlgorithm}




\inputleannode{lem:sumRewards_bestArm_le_of_arm_mul_eq}




\inputleannode{lem:prob_etc_error_le_exp}




\inputleannode{thm:regret_etc_le}


