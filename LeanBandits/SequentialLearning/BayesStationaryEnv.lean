/-
Copyright (c) 2026 RÃ©my Degenne. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: RÃ©my Degenne, Paulo Rauber
-/
import LeanBandits.Bandit.Regret
import LeanBandits.ForMathlib.MeasurableArgMax
import LeanBandits.SequentialLearning.StationaryEnv

/-! # Bayesian stationary environments -/

open MeasureTheory ProbabilityTheory Finset

namespace Learning

variable {ğ“” Î± R Î© : Type*}
variable [MeasurableSpace ğ“”] [MeasurableSpace Î±] [MeasurableSpace R] [MeasurableSpace Î©]

structure IsBayesAlgEnvSeq
    [StandardBorelSpace Î±] [Nonempty Î±] [StandardBorelSpace R] [Nonempty R]
    (Q : Measure ğ“”) (Îº : Kernel (ğ“” Ã— Î±) R) (alg : Algorithm Î± R)
    (E : Î© â†’ ğ“”) (A : â„• â†’ Î© â†’ Î±) (R' : â„• â†’ Î© â†’ R)
    (P : Measure Î©) [IsFiniteMeasure P] : Prop where
  measurable_E : Measurable E := by fun_prop
  measurable_A n : Measurable (A n) := by fun_prop
  measurable_R n : Measurable (R' n) := by fun_prop
  hasLaw_env : HasLaw E Q P
  hasCondDistrib_action_zero : HasCondDistrib (A 0) E (Kernel.const _ alg.p0) P
  hasCondDistrib_reward_zero : HasCondDistrib (R' 0) (fun Ï‰ â†¦ (E Ï‰, A 0 Ï‰)) Îº P
  hasCondDistrib_action n :
    HasCondDistrib (A (n + 1)) (fun Ï‰ â†¦ (E Ï‰, IsAlgEnvSeq.hist A R' n Ï‰))
      ((alg.policy n).prodMkLeft _) P
  hasCondDistrib_reward n :
    HasCondDistrib (R' (n + 1)) (fun Ï‰ â†¦ (IsAlgEnvSeq.hist A R' n Ï‰, E Ï‰, A (n + 1) Ï‰))
      (Îº.prodMkLeft _) P

namespace IsBayesAlgEnvSeq

def trajectory (A : â„• â†’ Î© â†’ Î±) (R' : â„• â†’ Î© â†’ R) (Ï‰ : Î©) : â„• â†’ Î± Ã— R := fun n â†¦ (A n Ï‰, R' n Ï‰)

@[fun_prop]
lemma measurable_trajectory {A : â„• â†’ Î© â†’ Î±} {R' : â„• â†’ Î© â†’ R} (hA : âˆ€ n, Measurable (A n))
    (hR : âˆ€ n, Measurable (R' n)) : Measurable (trajectory A R') := by
  unfold trajectory
  fun_prop

section Real

noncomputable
def actionMean (Îº : Kernel (ğ“” Ã— Î±) â„) (E : Î© â†’ ğ“”) (a : Î±) (Ï‰ : Î©) : â„ := (Îº (E Ï‰, a))[id]

@[fun_prop]
lemma measurable_actionMean {Îº : Kernel (ğ“” Ã— Î±) â„} {E : Î© â†’ ğ“”} {a : Î±} (hE : Measurable E) :
    Measurable (actionMean Îº E a) :=
  stronglyMeasurable_id.integral_kernel.measurable.comp (by fun_prop)

noncomputable
def bestAction [Nonempty Î±] [Fintype Î±] [Encodable Î±] [MeasurableSingletonClass Î±]
    (Îº : Kernel (ğ“” Ã— Î±) â„) (E : Î© â†’ ğ“”) (Ï‰ : Î©) : Î± :=
  measurableArgmax (fun Ï‰' a â†¦ actionMean Îº E a Ï‰') Ï‰

@[fun_prop]
lemma measurable_bestAction [Nonempty Î±] [Fintype Î±] [Encodable Î±] [MeasurableSingletonClass Î±]
    {Îº : Kernel (ğ“” Ã— Î±) â„} {E : Î© â†’ ğ“”} (hE : Measurable E) : Measurable (bestAction Îº E) :=
  measurable_measurableArgmax (by fun_prop)

noncomputable
def regret (Îº : Kernel (ğ“” Ã— Î±) â„) (E : Î© â†’ ğ“”) (A : â„• â†’ Î© â†’ Î±) (t : â„•) (Ï‰ : Î©) : â„ :=
  Bandits.regret (Îº.sectR (E Ï‰)) A t Ï‰

@[fun_prop]
lemma measurable_regret [Countable Î±] {Îº : Kernel (ğ“” Ã— Î±) â„} {E : Î© â†’ ğ“”} {A : â„• â†’ Î© â†’ Î±} {t : â„•}
    (hE : Measurable E) (hA : âˆ€ n, Measurable (A n)) :
    Measurable (regret Îº E A t) := by
  have hm := (stronglyMeasurable_id.integral_kernel (Îº := Îº)).measurable
  exact (Measurable.const_mul (Measurable.iSup fun _ â†¦ (hm.comp (by fun_prop))) _).sub
    (Finset.measurable_sum _ fun _ _ â†¦ hm.comp (by fun_prop))

end Real

variable [StandardBorelSpace Î±] [Nonempty Î±] [StandardBorelSpace R] [Nonempty R]
variable {Q : Measure ğ“”} {Îº : Kernel (ğ“” Ã— Î±) R} {alg : Algorithm Î± R}
variable {E : Î© â†’ ğ“”} {A : â„• â†’ Î© â†’ Î±} {R' : â„• â†’ Î© â†’ R}
variable {P : Measure Î©} [IsFiniteMeasure P]

section Laws

lemma hasLaw_action_zero [IsProbabilityMeasure P] (h : IsBayesAlgEnvSeq Q Îº alg E A R' P) :
    HasLaw (A 0) alg.p0 P := h.hasCondDistrib_action_zero.hasLaw_of_const

lemma hasCondDistrib_action' (h : IsBayesAlgEnvSeq Q Îº alg E A R' P) (n : â„•) :
    HasCondDistrib (A (n + 1)) (IsAlgEnvSeq.hist A R' n) (alg.policy n) P :=
  (h.hasCondDistrib_action n).comp_left (by fun_prop)

lemma hasCondDistrib_reward' [IsFiniteKernel Îº] (h : IsBayesAlgEnvSeq Q Îº alg E A R' P) (n : â„•) :
    HasCondDistrib (R' (n + 1)) (fun Ï‰ â†¦ (E Ï‰, A (n + 1) Ï‰)) Îº P :=
  (h.hasCondDistrib_reward n).comp_left (by fun_prop)

end Laws

section CondDistribIsAlgEnvSeq

lemma hasLaw_IT_action_zero (h : IsBayesAlgEnvSeq Q Îº alg E A R' P) :
    âˆ€áµ e âˆ‚Q, HasLaw (IT.action 0) alg.p0 (condDistrib (trajectory A R') E P e) := by
  rw [â† h.hasLaw_env.map_eq]
  filter_upwards [condDistrib_comp E
      (measurable_trajectory h.measurable_A h.measurable_R).aemeasurable
      (IT.measurable_action (Î± := Î±) (R := R) 0),
    h.hasCondDistrib_action_zero.condDistrib_eq] with e hc hcd
  exact âŸ¨(IT.measurable_action 0).aemeasurable, by
    rw [â† Kernel.map_apply _ (IT.measurable_action 0), â† hc,
      show IT.action 0 âˆ˜ trajectory A R' = A 0 from rfl, hcd, Kernel.const_apply]âŸ©

lemma hasCondDistrib_IT_reward_zero [IsFiniteKernel Îº] (h : IsBayesAlgEnvSeq Q Îº alg E A R' P) :
    âˆ€áµ e âˆ‚Q, HasCondDistrib (IT.reward 0) (IT.action 0) (Îº.sectR e)
      (condDistrib (trajectory A R') E P e) := by
  rw [â† h.hasLaw_env.map_eq]
  exact h.hasCondDistrib_reward_zero.ae_hasCondDistrib_sectR
    (IT.measurable_action 0) (IT.measurable_reward 0)
    (measurable_trajectory h.measurable_A h.measurable_R).aemeasurable
    h.measurable_E.aemeasurable

lemma hasCondDistrib_IT_action (h : IsBayesAlgEnvSeq Q Îº alg E A R' P) (n : â„•) :
    âˆ€áµ e âˆ‚Q, HasCondDistrib (IT.action (n + 1)) (IT.hist n) (alg.policy n)
      (condDistrib (trajectory A R') E P e) := by
  rw [â† h.hasLaw_env.map_eq]
  filter_upwards [(h.hasCondDistrib_action n).ae_hasCondDistrib_sectR
    (IT.measurable_hist n) (IT.measurable_action (n + 1))
    (measurable_trajectory h.measurable_A h.measurable_R).aemeasurable
    h.measurable_E.aemeasurable] with e he
  rwa [Kernel.sectR_prodMkLeft] at he

lemma hasCondDistrib_IT_reward [IsFiniteKernel Îº] (h : IsBayesAlgEnvSeq Q Îº alg E A R' P) (n : â„•) :
    âˆ€áµ e âˆ‚Q, HasCondDistrib (IT.reward (n + 1)) (fun x â†¦ (IT.hist n x, IT.action (n + 1) x))
      ((Îº.sectR e).prodMkLeft _) (condDistrib (trajectory A R') E P e) := by
  rw [â† h.hasLaw_env.map_eq]
  have hmt := measurable_trajectory h.measurable_A h.measurable_R
  have hm := IsAlgEnvSeq.measurable_hist h.measurable_A h.measurable_R n
  have h_reorder : HasCondDistrib (R' (n + 1))
      (fun Ï‰ â†¦ ((IsAlgEnvSeq.hist A R' n Ï‰, A (n + 1) Ï‰), E Ï‰))
      ((Îº.prodMkLeft _).comap (fun ((h, a), e) â†¦ (h, (e, a))) (by fun_prop)) P := by
    convert (h.hasCondDistrib_reward n).comp_right
      ((MeasurableEquiv.prodCongr (.refl _) .prodComm).trans MeasurableEquiv.prodAssoc.symm) using 2
  filter_upwards [h_reorder.ae_hasCondDistrib_sectL
    ((IT.measurable_hist n).prodMk (IT.measurable_action (n + 1)))
    (IT.measurable_reward (n + 1))
    hmt.aemeasurable h.measurable_E.aemeasurable] with e he
  have hk : ((Îº.prodMkLeft _).comap (fun ((h, a), e) â†¦ (h, (e, a))) (by fun_prop)).sectL e =
      (Îº.sectR e).prodMkLeft (â†¥(Iic n) â†’ Î± Ã— R) :=
    Kernel.ext fun âŸ¨_, aâŸ© â†¦ by
      simp [Kernel.sectL_apply, Kernel.comap_apply, Kernel.prodMkLeft_apply]
  rw [hk] at he; exact he

lemma ae_IsAlgEnvSeq [IsMarkovKernel Îº] (h : IsBayesAlgEnvSeq Q Îº alg E A R' P) :
    âˆ€áµ e âˆ‚Q, IsAlgEnvSeq IT.action IT.reward alg (stationaryEnv (Îº.sectR e))
      (condDistrib (trajectory A R') E P e) := by
  filter_upwards [hasLaw_IT_action_zero h, hasCondDistrib_IT_reward_zero h,
    ae_all_iff.2 (hasCondDistrib_IT_action h), ae_all_iff.2 (hasCondDistrib_IT_reward h)]
    with _ h_a0 h_r0 h_a h_r
  exact {
    hasLaw_action_zero := h_a0
    hasCondDistrib_reward_zero := h_r0
    hasCondDistrib_action := h_a
    hasCondDistrib_reward := h_r
  }

end CondDistribIsAlgEnvSeq

end IsBayesAlgEnvSeq

section IsAlgEnvSeq

noncomputable
def bayesStationaryEnv (Q : Measure ğ“”) [IsProbabilityMeasure Q] (Îº : Kernel (ğ“” Ã— Î±) R)
    [IsMarkovKernel Îº] : Environment Î± (ğ“” Ã— R) where
  feedback n :=
    let g : (Iic n â†’ Î± Ã— ğ“” Ã— R) Ã— Î± â†’ ğ“” Ã— Î± := fun (h, a) => ((h âŸ¨0, by simpâŸ©).2.1, a)
    (Kernel.deterministic (Prod.fst âˆ˜ g) (by fun_prop)) Ã—â‚– (Îº.comap g (by fun_prop))
  Î½0 := (Kernel.const _ Q) âŠ—â‚– Îº.swapLeft

variable [Nonempty Î±] [Nonempty ğ“”] [Nonempty R]
variable [StandardBorelSpace Î±] [StandardBorelSpace ğ“”] [StandardBorelSpace R]
variable {Q : Measure ğ“”} [IsProbabilityMeasure Q] {Îº : Kernel (ğ“” Ã— Î±) R} [IsMarkovKernel Îº]
variable {alg : Algorithm Î± R} {A : â„• â†’ Î© â†’ Î±} {R' : â„• â†’ Î© â†’ ğ“” Ã— R}
variable {P : Measure Î©} [IsProbabilityMeasure P]

lemma IsAlgEnvSeq.isBayesAlgEnvSeq
    (h : IsAlgEnvSeq A R' (alg.prod_left ğ“”) (bayesStationaryEnv Q Îº) P) :
    IsBayesAlgEnvSeq Q Îº alg (fun Ï‰ â†¦ (R' 0 Ï‰).1) A (fun n Ï‰ â†¦ (R' n Ï‰).2) P where
  measurable_E := (h.measurable_R 0).fst
  measurable_A := h.measurable_A
  measurable_R n := (h.measurable_R n).snd
  hasLaw_env := by
    apply HasCondDistrib.hasLaw_of_const
    simpa [bayesStationaryEnv] using h.hasCondDistrib_reward_zero.fst
  hasCondDistrib_action_zero := by
    have hfst : HasCondDistrib (fun Ï‰ â†¦ (R' 0 Ï‰).1) (A 0) (Kernel.const Î± Q) P := by
      simpa [bayesStationaryEnv] using h.hasCondDistrib_reward_zero.fst
    simpa [h.hasLaw_action_zero.map_eq, Algorithm.prod_left] using hfst.swap_const
  hasCondDistrib_reward_zero := by
    have h0 := h.hasCondDistrib_reward_zero
    simp only [bayesStationaryEnv] at h0
    convert h0.of_compProd.comp_right (MeasurableEquiv.prodComm : Î± Ã— ğ“” â‰ƒáµ ğ“” Ã— Î±) using 2
  hasCondDistrib_action n := by
    let f : (Iic n â†’ Î± Ã— ğ“” Ã— R) â†’ ğ“” Ã— (Iic n â†’ Î± Ã— R) :=
      fun h â†¦ ((h âŸ¨0, by simpâŸ©).2.1, fun i â†¦ ((h i).1, (h i).2.2))
    suffices h' : HasCondDistrib (A (n + 1)) (IsAlgEnvSeq.hist A R' n)
        (((alg.policy n).comap Prod.snd (by fun_prop)).comap f (by fun_prop)) P from
      h'.comp_left (f := f)
    exact h.hasCondDistrib_action n
  hasCondDistrib_reward n := by
    let f : (Iic n â†’ Î± Ã— ğ“” Ã— R) Ã— Î± â†’ (Iic n â†’ Î± Ã— R) Ã— ğ“” Ã— Î± :=
      fun p â†¦ ((fun i â†¦ ((p.1 i).1, (p.1 i).2.2)), (p.1 âŸ¨0, by simpâŸ©).2.1, p.2)
    have hf : Measurable f := by fun_prop
    suffices h' : HasCondDistrib (fun Ï‰ â†¦ (R' (n + 1) Ï‰).2)
        (fun Ï‰ â†¦ (IsAlgEnvSeq.hist A R' n Ï‰, A (n + 1) Ï‰))
        ((Kernel.prodMkLeft (â†¥(Iic n) â†’ Î± Ã— R) Îº).comap f hf) P from h'.comp_left hf
    simpa [bayesStationaryEnv, Kernel.snd_prod] using (h.hasCondDistrib_reward n).snd

end IsAlgEnvSeq

namespace IT

noncomputable
def bayesTrajMeasure (Q : Measure ğ“”) [IsProbabilityMeasure Q] (Îº : Kernel (ğ“” Ã— Î±) R)
    [IsMarkovKernel Îº] (alg : Algorithm Î± R) : Measure (â„• â†’ Î± Ã— ğ“” Ã— R) :=
  trajMeasure (alg.prod_left ğ“”) (bayesStationaryEnv Q Îº)
deriving IsProbabilityMeasure

lemma isBayesAlgEnvSeq_bayesTrajMeasure
    [StandardBorelSpace Î±] [Nonempty Î±]
    [StandardBorelSpace ğ“”] [Nonempty ğ“”]
    [StandardBorelSpace R] [Nonempty R]
    (Q : Measure ğ“”) [IsProbabilityMeasure Q] (Îº : Kernel (ğ“” Ã— Î±) R) [IsMarkovKernel Îº]
    (alg : Algorithm Î± R) :
    IsBayesAlgEnvSeq Q Îº alg (fun Ï‰ â†¦ (Ï‰ 0).2.1) action (fun n Ï‰ â†¦ (Ï‰ n).2.2)
       (bayesTrajMeasure Q Îº alg) :=
  (isAlgEnvSeq_trajMeasure _ _).isBayesAlgEnvSeq

noncomputable
def bayesTrajMeasurePosterior [StandardBorelSpace ğ“”] [Nonempty ğ“”]
    (Q : Measure ğ“”) [IsProbabilityMeasure Q] (Îº : Kernel (ğ“” Ã— Î±) â„) [IsMarkovKernel Îº]
    (alg : Algorithm Î± â„) (n : â„•) : Kernel (Iic n â†’ Î± Ã— â„) ğ“” :=
  condDistrib (fun Ï‰ â†¦ (Ï‰ 0).2.1) (IsAlgEnvSeq.hist action (fun n Ï‰ â†¦ (Ï‰ n).2.2) n)
    (bayesTrajMeasure Q Îº alg)
deriving IsMarkovKernel

end IT

end Learning
