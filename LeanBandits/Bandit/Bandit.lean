/-
Copyright (c) 2025 Rémy Degenne. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: Rémy Degenne, Paulo Rauber
-/
import LeanBandits.SequentialLearning.Deterministic
import Mathlib.Probability.IdentDistrib
import Mathlib.Probability.Independence.InfinitePi

/-!
# Bandit
-/

open MeasureTheory ProbabilityTheory Filter Real Finset Learning

open scoped ENNReal NNReal

namespace Bandits

variable {α R : Type*} {mα : MeasurableSpace α} {mR : MeasurableSpace R}

section MeasureSpace

namespace Bandit

/-- Kernel describing the distribution of the next arm-reward pair given the history up to `n`. -/
noncomputable
def stepKernel (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    Kernel (Iic n → α × R) (α × R) :=
  Learning.stepKernel alg (stationaryEnv ν) n
deriving IsMarkovKernel

@[simp]
lemma fst_stepKernel (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    (stepKernel alg ν n).fst = alg.policy n := by
  rw [stepKernel, Learning.fst_stepKernel]

@[simp]
lemma snd_stepKernel (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    (stepKernel alg ν n).snd = ν ∘ₖ alg.policy n := by
  rw [stepKernel, Learning.stepKernel, stationaryEnv_feedback, Kernel.snd_compProd_prodMkLeft]

/-- Measure on the sequence of arms pulled and rewards observed generated by the bandit. -/
noncomputable
def trajMeasure (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] : Measure (ℕ → α × R) :=
  Kernel.trajMeasure (alg.p0 ⊗ₘ ν) (stepKernel alg ν)
deriving IsProbabilityMeasure

/-- Measure of an infinite stream of rewards from each arm. -/
noncomputable
def streamMeasure (ν : Kernel α R) [IsMarkovKernel ν] : Measure (ℕ → α → R) :=
  Measure.infinitePi fun _ ↦ Measure.infinitePi ν
deriving IsProbabilityMeasure

/-- Joint distribution of the sequence of arm pulled and rewards, and a stream of independent
rewards from all arms. -/
noncomputable
def measure (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] :
    Measure ((ℕ → α × R) × (ℕ → α → R)) :=
  (trajMeasure alg ν).prod (streamMeasure ν)
deriving IsProbabilityMeasure

@[simp]
lemma fst_measure (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] :
    (measure alg ν).fst = trajMeasure alg ν := by
  rw [measure, Measure.fst_prod]

@[simp]
lemma snd_measure (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] :
    (measure alg ν).snd = streamMeasure ν := by
  rw [measure, Measure.snd_prod]

end Bandit

section StreamMeasure

lemma _root_.hasLaw_eval_infinitePi {ι : Type*} {X : ι → Type*} {mX : ∀ i, MeasurableSpace (X i)}
  (μ : (i : ι) → Measure (X i)) [hμ : ∀ i, IsProbabilityMeasure (μ i)] (i : ι) :
    HasLaw (Function.eval i) (μ i) (Measure.infinitePi μ) where
  aemeasurable := Measurable.aemeasurable (by fun_prop)
  map_eq := by exact (measurePreserving_eval_infinitePi μ i).map_eq

lemma hasLaw_eval_streamMeasure (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    HasLaw (fun h : ℕ → α → R ↦ h n) (Measure.infinitePi ν) (Bandit.streamMeasure ν) :=
  hasLaw_eval_infinitePi (fun _ ↦ Measure.infinitePi ν) n

lemma hasLaw_eval_eval_streamMeasure (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) (a : α) :
    HasLaw (fun h : ℕ → α → R ↦ h n a) (ν a) (Bandit.streamMeasure ν) :=
  (hasLaw_eval_infinitePi ν a).comp (hasLaw_eval_streamMeasure ν n)

lemma identDistrib_eval_eval_id_streamMeasure (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) (a : α) :
    IdentDistrib (fun h : ℕ → α → R ↦ h n a) id (Bandit.streamMeasure ν) (ν a) where
  aemeasurable_fst := Measurable.aemeasurable (by fun_prop)
  aemeasurable_snd := Measurable.aemeasurable (by fun_prop)
  map_eq := by
    rw [← (hasLaw_eval_eval_streamMeasure ν n a).map_eq,
      Measure.map_map (by fun_prop) (by fun_prop)]
    simp

lemma Integrable.congr_identDistrib {Ω Ω' : Type*}
    {mΩ : MeasurableSpace Ω} {mΩ' : MeasurableSpace Ω'}
    {μ : Measure Ω} {μ' : Measure Ω'} {X : Ω → ℝ} {Y : Ω' → ℝ}
    (hX : Integrable X μ) (hXY : IdentDistrib X Y μ μ') :
    Integrable Y μ' := by
  have hX' : Integrable id (μ.map X) := by
    rwa [integrable_map_measure (by fun_prop) hXY.aemeasurable_fst]
  rw [hXY.map_eq] at hX'
  rwa [integrable_map_measure (by fun_prop) hXY.aemeasurable_snd] at hX'

lemma integrable_eval_streamMeasure (ν : Kernel α ℝ) [IsMarkovKernel ν] (n : ℕ) (a : α)
    (h_int : Integrable id (ν a)) :
    Integrable (fun h : ℕ → α → ℝ ↦ h n a) (Bandit.streamMeasure ν) :=
  Integrable.congr_identDistrib h_int (identDistrib_eval_eval_id_streamMeasure ν n a).symm

lemma integral_eval_streamMeasure (ν : Kernel α ℝ) [IsMarkovKernel ν] (n : ℕ) (a : α) :
    ∫ h, h n a ∂(Bandit.streamMeasure ν) = (ν a)[id] := by
  calc ∫ h, h n a ∂(Bandit.streamMeasure ν)
  _ = ∫ x, x ∂((Bandit.streamMeasure ν).map (fun h ↦ h n a)) := by
    rw [integral_map (Measurable.aemeasurable (by fun_prop)) (by fun_prop)]
  _ = (ν a)[id] := by simp [(hasLaw_eval_eval_streamMeasure ν n a).map_eq]

lemma iIndepFun_eval_streamMeasure' (ν : Kernel α R) [IsMarkovKernel ν] :
    iIndepFun (fun n ω ↦ ω n) (Bandit.streamMeasure ν) :=
  iIndepFun_infinitePi (μ := fun (_ : ℕ) ↦ Measure.infinitePi ν) (Ω := fun _ ↦ α → R)
    (X := fun i u ↦ u) (fun i ↦ by fun_prop)

lemma iIndepFun_eval_streamMeasure'' (ν : Kernel α R) [IsMarkovKernel ν] (a : α) :
    iIndepFun (fun n ω ↦ ω n a) (Bandit.streamMeasure ν) :=
  (iIndepFun_eval_streamMeasure' ν).comp (g := fun i ω ↦ ω a) (by fun_prop)

lemma iIndepFun_eval_streamMeasure (ν : Kernel α R) [IsMarkovKernel ν] :
    iIndepFun (fun (p : ℕ × α) ω ↦ ω p.1 p.2) (Bandit.streamMeasure ν) := by
  have h_ind := iIndepFun_eval_streamMeasure' ν
  sorry -- essentially done by Etienne in Mathlib PRs

lemma indepFun_eval_streamMeasure (ν : Kernel α R) [IsMarkovKernel ν] {n m : ℕ} {a b : α}
    (h : n ≠ m ∨ a ≠ b) :
    IndepFun (fun ω ↦ ω n a) (fun ω ↦ ω m b) (Bandit.streamMeasure ν) := by
  change IndepFun (fun ω ↦ ω (n, a).1 (n, a).2) (fun ω ↦ ω (m, b).1 (m, b).2)
    (Bandit.streamMeasure ν)
  exact (iIndepFun_eval_streamMeasure ν).indepFun (by grind)

lemma indepFun_eval_streamMeasure' (ν : Kernel α R) [IsMarkovKernel ν] {a b : α} (h : a ≠ b) :
    IndepFun (fun ω n ↦ ω n a) (fun ω n ↦ ω n b) (Bandit.streamMeasure ν) := by
  sorry

lemma indepFun_eval_snd_measure (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν]
    {a b : α} (h : a ≠ b) :
    IndepFun (fun ω n ↦ ω.2 n a) (fun ω n ↦ ω.2 n b) (Bandit.measure alg ν) := by
  refine indepFun_snd_prod ?_ ?_ (indepFun_eval_streamMeasure' ν h) (Bandit.trajMeasure alg ν)
  · exact Measurable.aemeasurable (by fun_prop)
  · exact Measurable.aemeasurable (by fun_prop)

end StreamMeasure

/-- `arm n` is the arm pulled at time `n`. This is a random variable on the measurable space
`ℕ → α × ℝ`. -/
def arm (n : ℕ) (h : ℕ → α × R) : α := (h n).1

/-- `reward n` is the reward at time `n`. This is a random variable on the measurable space
`ℕ → α × R`. -/
def reward (n : ℕ) (h : ℕ → α × R) : R := (h n).2

/-- `hist n` is the history up to time `n`. This is a random variable on the measurable space
`ℕ → α × R`. -/
def hist (n : ℕ) (h : ℕ → α × R) : Iic n → α × R := fun i ↦ h i

@[fun_prop]
lemma measurable_arm (n : ℕ) : Measurable (arm n (α := α) (R := R)) := measurable_action n

@[fun_prop]
lemma measurable_arm_prod : Measurable (fun p : ℕ × (ℕ → α × R) ↦ arm p.1 p.2) :=
  measurable_action_prod

@[fun_prop]
lemma measurable_reward (n : ℕ) : Measurable (reward n (α := α) (R := R)) :=
  Learning.measurable_reward n

@[fun_prop]
lemma measurable_reward_prod : Measurable (fun p : ℕ × (ℕ → α × R) ↦ reward p.1 p.2) :=
  Learning.measurable_reward_prod

@[fun_prop]
lemma measurable_hist (n : ℕ) : Measurable (hist n (α := α) (R := R)) :=
  Learning.measurable_hist n

lemma hist_eq_frestrictLe :
    hist = Preorder.frestrictLe («π» := fun _ ↦ α × R) := by
  ext n h i : 3
  simp [hist, Preorder.frestrictLe]

/-- Filtration of the bandit process. -/
protected def filtration (α R : Type*) [MeasurableSpace α] [MeasurableSpace R] :
    Filtration ℕ (inferInstance : MeasurableSpace (ℕ → α × R)) :=
  MeasureTheory.Filtration.piLE (X := fun _ ↦ α × R)

section Laws

lemma hasLaw_step_zero (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] :
    HasLaw (fun h : ℕ → α × R ↦ h 0) (alg.p0 ⊗ₘ ν) (Bandit.trajMeasure alg ν) :=
  Learning.hasLaw_step_zero alg (stationaryEnv ν)

lemma hasLaw_arm_zero (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] :
    HasLaw (arm 0) alg.p0 (Bandit.trajMeasure alg ν) :=
  Learning.hasLaw_action_zero alg (stationaryEnv ν)

lemma condDistrib_arm_reward [StandardBorelSpace α] [Nonempty α] [StandardBorelSpace R] [Nonempty R]
    (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    condDistrib (fun h ↦ (arm (n + 1) h, reward (n + 1) h)) (hist n) (Bandit.trajMeasure alg ν)
      =ᵐ[(Bandit.trajMeasure alg ν).map (hist n)] Bandit.stepKernel alg ν n :=
  Learning.condDistrib_step alg (stationaryEnv ν) n

lemma condDistrib_reward' [StandardBorelSpace α] [Nonempty α] [StandardBorelSpace R] [Nonempty R]
    (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    condDistrib (reward (n + 1)) (fun ω ↦ (hist n ω, arm (n + 1) ω)) (Bandit.trajMeasure alg ν)
      =ᵐ[(Bandit.trajMeasure alg ν).map (fun ω ↦ (hist n ω, arm (n + 1) ω))] ν.prodMkLeft _ :=
  Learning.condDistrib_reward alg (stationaryEnv ν) n

lemma condDistrib_reward [StandardBorelSpace α] [Nonempty α] [StandardBorelSpace R] [Nonempty R]
    (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    condDistrib (reward n) (arm n) (Bandit.trajMeasure alg ν)
      =ᵐ[(Bandit.trajMeasure alg ν).map (arm n)] ν :=
   Learning.condDistrib_reward_stationaryEnv n

lemma condDistrib_arm [StandardBorelSpace α] [Nonempty α] [StandardBorelSpace R] [Nonempty R]
    (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    condDistrib (arm (n + 1)) (hist n) (Bandit.trajMeasure alg ν)
      =ᵐ[(Bandit.trajMeasure alg ν).map (hist n)] alg.policy n :=
  Learning.condDistrib_action alg (stationaryEnv ν) n

/-- The reward at time `n+1` is independent of the history up to time `n` given the arm at `n+1`. -/
lemma condIndepFun_reward_hist_arm [StandardBorelSpace α] [Nonempty α]
    [StandardBorelSpace R] [Nonempty R]
    {alg : Algorithm α R} {ν : Kernel α R} [IsMarkovKernel ν] (n : ℕ) :
    CondIndepFun (MeasurableSpace.comap (arm (n + 1)) inferInstance)
      (measurable_arm _).comap_le (reward (n + 1)) (hist n) (Bandit.trajMeasure alg ν) :=
  Learning.condIndepFun_reward_hist_action n

end Laws

section DetAlgorithm

variable {nextArm : (n : ℕ) → (Iic n → α × R) → α} {h_next : ∀ n, Measurable (nextArm n)}
  {arm0 : α} {ν : Kernel α R} [IsMarkovKernel ν]

local notation "𝔓t" => Bandit.trajMeasure (detAlgorithm nextArm h_next arm0) ν

lemma HasLaw_arm_zero_detAlgorithm : HasLaw (arm 0) (Measure.dirac arm0) 𝔓t where
  map_eq := (hasLaw_arm_zero _ _).map_eq

lemma arm_zero_detAlgorithm [MeasurableSingletonClass α] :
    arm 0 =ᵐ[𝔓t] fun _ ↦ arm0 := by
  have h_eq : ∀ᵐ x ∂(((𝔓t).map (arm 0))), x = arm0 := by
    rw [(hasLaw_arm_zero _ _).map_eq]
    simp [detAlgorithm]
  exact ae_of_ae_map (by fun_prop) h_eq

lemma arm_detAlgorithm_ae_eq [StandardBorelSpace α] [Nonempty α]
    [StandardBorelSpace R] [Nonempty R] (n : ℕ) :
    arm (n + 1) =ᵐ[𝔓t] fun h ↦ nextArm n (fun i ↦ h i) :=
  Learning.action_detAlgorithm_ae_eq n

example [StandardBorelSpace α] [Nonempty α]
    [StandardBorelSpace R] [Nonempty R] :
    ∀ᵐ h ∂(𝔓t), arm 0 h = arm0 ∧ ∀ n, arm (n + 1) h = nextArm n (fun i ↦ h i) := by
  rw [eventually_and, ae_all_iff]
  exact ⟨arm_zero_detAlgorithm, arm_detAlgorithm_ae_eq⟩

end DetAlgorithm

end MeasureSpace

end Bandits
