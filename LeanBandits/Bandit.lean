/-
Copyright (c) 2025 Rémy Degenne. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: Rémy Degenne, Paulo Rauber
-/
import Mathlib

/-!
# Bandit

-/

open MeasureTheory ProbabilityTheory Filter Real Finset

open scoped ENNReal NNReal

/-- Measurable equivalence between `Iic 0 → α` and `α`. -/
def MeasurableEquiv.piIicZero (α : Type*) [MeasurableSpace α] :
    (Iic 0 → α) ≃ᵐ α :=
  have : Unique (Iic 0) := by simp only [mem_Iic, nonpos_iff_eq_zero]; exact Unique.subtypeEq 0
  MeasurableEquiv.funUnique _ _

namespace Bandits

variable {α R : Type*} {mα : MeasurableSpace α} {mR : MeasurableSpace R}

section MeasureSpace

/-- A stochastic, sequential algorithm. -/
structure Algorithm (α R : Type*) [MeasurableSpace α] [MeasurableSpace R] where
  /-- Policy or sampling rule: distribution of the next pull. -/
  policy : (n : ℕ) → Kernel (Iic n → α × R) α
  [h_policy : ∀ n, IsMarkovKernel (policy n)]
  /-- Distribution of the first pull. -/
  p0 : Measure α
  [hp0 : IsProbabilityMeasure p0]

instance (alg : Algorithm α R) (n : ℕ) : IsMarkovKernel (alg.policy n) := alg.h_policy n
instance (alg : Algorithm α R) : IsProbabilityMeasure alg.p0 := alg.hp0

namespace Bandit

/-- Kernel describing the distribution of the next arm-reward pair given the history up to `n`. -/
noncomputable
def stepKernel (alg : Algorithm α R) (ν : Kernel α R) (n : ℕ) : Kernel (Iic n → α × R) (α × R) :=
  (alg.policy n) ⊗ₖ ν.prodMkLeft (Iic n → α × R)

instance (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    IsMarkovKernel (stepKernel alg ν n) := by
  rw [stepKernel]
  infer_instance

@[simp]
lemma fst_stepKernel (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    (stepKernel alg ν n).fst = alg.policy n := by
  rw [stepKernel, Kernel.fst_compProd]

@[simp]
lemma snd_stepKernel (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    (stepKernel alg ν n).snd = ν ∘ₖ alg.policy n := by
  rw [stepKernel, Kernel.snd_compProd_prodMkLeft]

/-- Kernel sending a partial trajectory of the bandit interaction `Iic n → α × ℝ` to a measure
on `ℕ → α × ℝ`, supported on full trajectories that start with the partial one. -/
noncomputable def traj (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    Kernel (Iic n → α × R) (ℕ → α × R) :=
  ProbabilityTheory.Kernel.traj (X := fun _ ↦ α × R) (stepKernel alg ν) n
deriving IsMarkovKernel

/-- Measure on the sequence of arms pulled and rewards observed generated by the bandit. -/
noncomputable
def trajMeasure (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] : Measure (ℕ → α × R) :=
  (traj alg ν 0) ∘ₘ ((alg.p0 ⊗ₘ ν).map (MeasurableEquiv.piIicZero _).symm)

/-- Measure of an infinite stream of rewards from each arm. -/
noncomputable
def streamMeasure (ν : Kernel α R) [IsMarkovKernel ν] : Measure (ℕ → α → R) :=
  Measure.infinitePi fun _ ↦ Measure.infinitePi ν
deriving IsProbabilityMeasure

instance (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] :
    IsProbabilityMeasure (trajMeasure alg ν) := by
  rw [trajMeasure]
  have : IsProbabilityMeasure ((alg.p0 ⊗ₘ ν).map (MeasurableEquiv.piIicZero _).symm) :=
    isProbabilityMeasure_map <| by fun_prop
  infer_instance

/-- Joint distribution of the sequence of arm pulled and rewards, and a stream of independent
rewards from all arms. -/
noncomputable
def measure (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] :
    Measure ((ℕ → α × R) × (ℕ → α → R)) :=
  (trajMeasure alg ν).prod (streamMeasure ν)
deriving IsProbabilityMeasure

end Bandit

/-- `arm n` is the arm pulled at time `n`. This is a random variable on the measurable space
`ℕ → α × ℝ`. -/
def arm (n : ℕ) (h : ℕ → α × R) : α := (h n).1

/-- `reward n` is the reward at time `n`. This is a random variable on the measurable space
`ℕ → α × R`. -/
def reward (n : ℕ) (h : ℕ → α × R) : R := (h n).2

/-- `hist n` is the history up to time `n`. This is a random variable on the measurable space
`ℕ → α × R`. -/
def hist (n : ℕ) (h : ℕ → α × R) : Iic n → α × R := fun i ↦ h i

@[fun_prop]
lemma measurable_arm (n : ℕ) : Measurable (arm n (α := α) (R := R)) := by unfold arm; fun_prop

@[fun_prop]
lemma measurable_reward (n : ℕ) : Measurable (reward n (α := α) (R := R)) := by
  unfold reward; fun_prop

@[fun_prop]
lemma measurable_hist (n : ℕ) : Measurable (hist n (α := α) (R := R)) := by unfold hist; fun_prop

/-- Filtration of the bandit process. -/
def ℱ (α : Type*) [MeasurableSpace α] :
    Filtration ℕ (inferInstance : MeasurableSpace (ℕ → α × R)) :=
  MeasureTheory.Filtration.piLE (X := fun _ ↦ α × R)

lemma condDistrib_arm_reward [StandardBorelSpace α] [Nonempty α] [StandardBorelSpace R] [Nonempty R]
    (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    condDistrib (fun h ↦ (arm (n + 1) h, reward (n + 1) h)) (hist n) (Bandit.trajMeasure alg ν)
      =ᵐ[(Bandit.trajMeasure alg ν).map (hist n)] Bandit.stepKernel alg ν n := by
  sorry

lemma condDistrib_reward [StandardBorelSpace R] [Nonempty R] (alg : Algorithm α R) (ν : Kernel α R)
    [IsMarkovKernel ν] (n : ℕ) :
    condDistrib (reward n) (arm n) (Bandit.trajMeasure alg ν)
      =ᵐ[(Bandit.trajMeasure alg ν).map (arm n)] ν := by
  sorry

lemma condDistrib_arm [StandardBorelSpace α] [Nonempty α] [StandardBorelSpace R] [Nonempty R]
    (alg : Algorithm α R) (ν : Kernel α R) [IsMarkovKernel ν] (n : ℕ) :
    condDistrib (arm (n + 1)) (hist n) (Bandit.trajMeasure alg ν)
      =ᵐ[(Bandit.trajMeasure alg ν).map (hist n)] alg.policy n := by
  sorry

end MeasureSpace

end Bandits
